{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python-opencv (from versions: none)\n",
      "ERROR: No matching distribution found for python-opencv\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# pip install python-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chap 1\n",
    "# library import\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"resources/image.jpg\")  # read image\n",
    "\n",
    "cv.imshow(\"Pehli Image\", img)  # takes img as input and name it as Pehli Image\n",
    "cv.waitKey(0)  # waits for infinite time for a key to be pressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap 2 - resize\n",
    "# library import\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "img1 = cv.resize(img, (800, 600))  # takes img as input and resize it to 800x600\n",
    "\n",
    "cv.imshow(\"Pehli Image\", img)  # takes img as input and shows the first image\n",
    "cv.imshow(\"Doosri Image\", img1) # takes img1 as input and shows the resized image\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()  # closes all the windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 3 = gray image\n",
    "\n",
    "import cv2 as cv\n",
    "from cv2 import cvtColor\n",
    "\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "img = cv.resize(img, (800, 600))\n",
    "\n",
    "# conversion\n",
    "gray_img = cvtColor(img, cv.COLOR_BGR2GRAY) # takes img as input and convert RBG image to gray\n",
    "\n",
    "# display code\n",
    "cv.imshow(\"Pehli Image\", img)\n",
    "cv.imshow(\"Gray Image\", gray_img)\n",
    "\n",
    "# delay code\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 4 = Image into Black and white image\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "\n",
    "# conversion\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "(thresh, binary) = cv.threshold(gray_img, 127, 255, cv.THRESH_BINARY)  # takes gray_img as input and convert it into black and white image\n",
    "\n",
    "cv.imshow(\"Original Image\", img)\n",
    "cv.imshow(\"Gray Image\", gray_img)\n",
    "cv.imshow(\"Black and White Image\", binary)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chapter 5 = Image saving and image writing\n",
    "\n",
    "from cv2 import imwrite\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "\n",
    "# conversion to gray\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# conversion to black and white\n",
    "(thresh, binary) = cv.threshold(gray_img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# resize (optional)\n",
    "binary = cv.resize(binary, (400, 500))\n",
    "\n",
    "# save image\n",
    "imwrite(\"resources/gray_image.jpg\", gray_img)  # takes gray_img as input and save it as gray_image.jpg\n",
    "imwrite(\"resources/binary_image.jpg\", binary)  # takes binary as input and save it as binary_image.jpg\n",
    "\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 6 = reading video\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(\"resources/video.mp4\")  # takes video.mp4 as input and store it in cap\n",
    "\n",
    "# indicates if the video is opened or not\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open video\")\n",
    "    exit()\n",
    "\n",
    "# reading and playing video\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # takes cap as input and store it in frame\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    cv.imshow('frame', frame)  # takes frame (of video) as input and display it\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):  # press q to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 7 = reading video and converting it into gray and black and white\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(\"resources/video.mp4\")  # takes video.mp4 as input and store it in cap\n",
    "\n",
    "# indicates if the video is opened or not\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open video\")\n",
    "    exit()\n",
    "\n",
    "# reading and playing video\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # takes cap as input and store it in frame\n",
    "    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)  # takes frame as input and convert it into gray\n",
    "    (thresh, binary) = cv.threshold(grayframe, 127, 255, cv.THRESH_BINARY)  # takes grayframe as input and convert it into black and white\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    cv.imshow('frame', binary)  # takes grayframe/binary as input and display it grayframe/binary\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):  # press q to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 8 = video saving and writing\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(\"resources/video.mp4\")  # takes video.mp4 as input and store it in cap\n",
    "\n",
    "# writing format, codec, video writer and file output\n",
    "# fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv.VideoWriter('resources/output.avi', cv.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height), isColor=False)\n",
    "\n",
    "# indicates if the video is opened or not\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open video\")\n",
    "    exit()\n",
    "\n",
    "# reading and playing video\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # takes cap as input and store it in frame\n",
    "    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)  # takes frame as input and convert it into gray\n",
    "    # (thresh, binary) = cv.threshold(grayframe, 127, 255, cv.THRESH_BINARY)  # takes grayframe as input and convert it into black and white\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    out.write(grayframe)  # takes frame as input and write it in output.avi\n",
    "    cv.imshow('frame', grayframe)  # takes grayframe/binary as input and display it grayframe/binary\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):  # press q to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 9 = how to capture a webcamera video\n",
    "\n",
    "# Step-1 Import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Step-2 Read the frames from the webcam\n",
    "cap = cv.VideoCapture(0) # 0 for default camera\n",
    "\n",
    "# indicates if the webcamera is opened or not\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open webcamera\")\n",
    "    exit()\n",
    "\n",
    "# read until video is completed\n",
    "# Step-3 Display frame by frame\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Display the resulting frame\n",
    "        cv.imshow(\"Frame\", frame)\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Step-4 When everything done, release or close easily\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 10 = how to capture a webcamera video and convert it into gray and black and white\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0) # 0 for default camera\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    (thresh, binary) = cv.threshold(grayframe, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    if ret == True:\n",
    "        cv.imshow(\"OriginalCam\", frame)\n",
    "        cv.imshow(\"GrayCam\", grayframe)\n",
    "        cv.imshow(\"BinaryCam\", binary)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 11 = Saving Webcamera Video and Writing\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(0)  # takes webcamera as input and store it in cap\n",
    "\n",
    "# writing format, codec, video writer and file output\n",
    "# fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv.VideoWriter('resources/web_output.avi', cv.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height)) #add isColor=False for gray\n",
    "\n",
    "# indicates if the video is opened or not\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open video\")\n",
    "    exit()\n",
    "\n",
    "# reading and playing video\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # takes cap as input and store it in frame\n",
    "    # grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)  # takes frame as input and convert it into gray\n",
    "    # (thresh, binary) = cv.threshold(grayframe, 127, 255, cv.THRESH_BINARY)  # takes grayframe as input and convert it into black and white\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    out.write(frame)  # takes frame as input and write it in output.avi\n",
    "    cv.imshow('frame', frame)  # takes grayframe/binary as input and display it grayframe/binary\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):  # press q to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 12 = Setting of camera or video properties\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0) # 0 for default camera\n",
    "\n",
    "# set the width and height, and brightness of the camera\n",
    "cap.set(3, 640)   # 3 for width\n",
    "cap.set(4, 480)   # 4 for height\n",
    "cap.set(10, 100)  # 10 for brightness\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    # grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # (thresh, binary) = cv.threshold(grayframe, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    if ret == True:\n",
    "        cv.imshow(\"OriginalCam\", frame)\n",
    "        # cv.imshow(\"GrayCam\", grayframe)\n",
    "        # cv.imshow(\"BinaryCam\", binary)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our original image is =  (512, 512, 3)\n",
      "The size of our image is:  (512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chapter 13 = basic fucntions or manipulations in opencv\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"resources/lena.png\")  # read image from resources folder\n",
    "# print(\"The size of our original image is = \", img.shape)\n",
    "\n",
    "\n",
    "\n",
    "# resize image\n",
    "imgResize = cv.resize(img, (300, 200))  # resize image (width, height)\n",
    "\n",
    "# gray image\n",
    "imgGray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)  # convert image into gray (BGR2GRAY)\n",
    "\n",
    "# blur image\n",
    "imgBlur = cv.GaussianBlur(img, (7, 7), 0)  # convert image into blur (odd number, odd number, sigmaX)\n",
    "\n",
    "# edge detection\n",
    "imgCanny = cv.Canny(img, 100, 100)  # convert image into edge detection (image, threshold1, threshold2)\n",
    "\n",
    "# dilation (increase the thickness of the edge)\n",
    "kernel = np.ones((3, 3), np.uint8) # create a kernel (matrix) of 5x5\n",
    "imgDilation = cv.dilate(imgCanny, kernel, iterations=1)  # convert image into dilation (image, kernel, iterations)\n",
    "\n",
    "# erosion (decrease the thickness of the edge)\n",
    "imgEroded = cv.erode(imgDilation, kernel, iterations=1)  # convert image into erosion (image, kernel, iterations)\n",
    "\n",
    "# crop image\n",
    "print(\"The size of our original image is: \", img.shape)  # print the shape of the image\n",
    "imgCrop = img[0:200, 100:500]  # crop image (height, width)\n",
    "\n",
    "\n",
    "\n",
    "# display image\n",
    "\n",
    "cv.imshow(\"Original\", img)  # display image\n",
    "# cv.imshow(\"Resized\", imgResize)  # display image\n",
    "# cv.imshow(\"Gray\", imgGray)  # display image\n",
    "# cv.imshow(\"Blur\", imgBlur)  # display image\n",
    "# cv.imshow(\"Canny\", imgCanny)  # display image\n",
    "# cv.imshow(\"Dilation\", imgDilation)  # display image\n",
    "# cv.imshow(\"Eroded\", imgEroded)  # display image\n",
    "cv.imshow(\"Crop\", imgCrop)  # display image\n",
    "\n",
    "cv.waitKey(0)  # wait for any key to exit\n",
    "cv.destroyAllWindows()  # destroy all windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 14 = Shapes and Texts\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# draw a canvas (zeros for black and ones for white)\n",
    "img = np.zeros((600, 600))  # create a black image (height, width)\n",
    "img1 = np.ones((600, 600))  # create a white image (height, width)\n",
    "# print(img.shape)  # print the shape of the image\n",
    "\n",
    "# add color to the canvas\n",
    "colored_img = np.zeros((600, 600, 3), np.uint8)  # create a black image (height, width, color)\n",
    "colored_img[:] = 0, 255, 0  # add color to the image (BGR)\n",
    "\n",
    "colored_img[100:300, 100:500] = 0, 0, 255  # add color to a specific area of the image (BGR)\n",
    "\n",
    "# colored_img1 = np.ones((512, 512, 3), np.uint8)  # create a white image (height, width, color)\n",
    "\n",
    "\n",
    "# draw a line\n",
    "cv.line(colored_img, (0, 0), (600, 600), (255, 0, 0), 30)  # draw a line (image, start point, end point, color, thickness)\n",
    "cv.line(colored_img, (0,0), (colored_img.shape[0], colored_img.shape[1]), (255, 255, 0), 20)  # draw a line (image, start point, end point, color, thickness)\n",
    "\n",
    "# draw an arrow\n",
    "cv.arrowedLine(colored_img, (200, 200), (400, 400), (0, 255, 255), 10)  # draw a arrowed line (image, start point, end point, color, thickness)\n",
    "\n",
    "# # draw a rectangle\n",
    "cv.rectangle(colored_img, (200, 50), (500, 200), (0, 200, 255), 10)  # draw a rectangle (image, start point, end point, color, thickness)\n",
    "\n",
    "# fill a rectangle\n",
    "cv.rectangle(colored_img, (200, 50), (500, 200), (0, 200, 255), -1)  # draw a rectangle (image, start point, end point, color, thickness)\n",
    "\n",
    "# cv.rectangle(colored_img, (200, 50), (500, 200), (0, 200, 255), cv.FILLED)  # draw a rectangle (image, start point, end point, color, thickness)\n",
    "\n",
    "# # draw a circle\n",
    "cv.circle(colored_img, (447, 63), 63, (255, 255, 255), -1)  # draw a circle (image, center, radius, color, thickness)\n",
    "\n",
    "# # draw a polygon\n",
    "# pts = np.array([[10, 5], [20, 30], [70, 20], [50, 10]], np.int32)  # create a array of points\n",
    "# pts = pts.reshape((-1, 1, 2))  # reshape the array\n",
    "# img = cv.polylines(img, [pts], True, (0, 255, 255), 3)  # draw a polygon (image, points, isClosed, color, thickness)\n",
    "\n",
    "# # write text\n",
    "font = cv.FONT_HERSHEY_SIMPLEX  # create a font\n",
    "cv.putText(colored_img, 'OpenCV', (10, 500), font, 2, (255, 255, 0), 3, cv.LINE_AA)  # write text (image, text, start point, font, fontScale, color, thickness, lineType)\n",
    "\n",
    "# cv.imshow(\"Image\", img)  # display image\n",
    "# cv.imshow(\"Image1\", img1)  # display image\n",
    "cv.imshow(\"Colored Image\", colored_img)  # display image\n",
    "\n",
    "cv.waitKey(0)  # wait for any key to exit\n",
    "cv.destroyAllWindows()  # destroy all windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 15 = Resolutions of webcam\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# get the resolution of the webcam\n",
    "cap = cv.VideoCapture(0)  # create a video capture object\n",
    "\n",
    "# resolution HD (1280, 720)\n",
    "\n",
    "def make_1080p(): # Full HD\n",
    "    cap.set(3, 1920)\n",
    "    cap.set(4, 1080)\n",
    "\n",
    "def make_720p(): # HD\n",
    "    cap.set(3, 1280)\n",
    "    cap.set(4, 720)\n",
    "\n",
    "def make_480p(): # VGA or SD\n",
    "    cap.set(3, 640)\n",
    "    cap.set(4, 480) # 480p\n",
    "\n",
    "# make_1080p()\n",
    "# make_720p()\n",
    "make_480p()\n",
    "\n",
    "# how to change the frame rate\n",
    "cap.set(5, 60)  # 60 fps\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # read the video capture object\n",
    "\n",
    "    if ret == True:\n",
    "        cv.imshow(\"Camera\", frame)  # display image\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):  # wait for 'q' key to exit\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # release the video capture object\n",
    "cv.destroyAllWindows()  # destroy all windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 16 = Saving HD recordings of webcam\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# get the resolution of the webcam\n",
    "cap = cv.VideoCapture(0)  # create a video capture object\n",
    "\n",
    "# resolution HD (1280, 720)\n",
    "\n",
    "def make_1080p(): # Full HD\n",
    "    cap.set(3, 1920)\n",
    "    cap.set(4, 1080)\n",
    "\n",
    "def make_720p(): # HD\n",
    "    cap.set(3, 1280)\n",
    "    cap.set(4, 720)\n",
    "\n",
    "def make_480p(): # VGA or SD\n",
    "    cap.set(3, 640)\n",
    "    cap.set(4, 480) # 480p\n",
    "\n",
    "# make_1080p()\n",
    "# make_720p()\n",
    "make_480p()\n",
    "\n",
    "# how to change the frame rate\n",
    "cap.set(5, 60)  # 60 fps\n",
    "\n",
    "\n",
    "# writing format, codec, video writer and file output\n",
    "# fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv.VideoWriter('resources/webcam_output.avi', cv.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height)) \n",
    "# 10 is the frame rate, (frame_width, frame_height) is the resolution, isColor=False is for black and white.\n",
    "\n",
    "# indicates if the video is opened or not\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open video\")\n",
    "    exit()\n",
    "\n",
    "# reading and playing video\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # takes cap as input and store it in frame\n",
    "    # grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)  # takes frame as input and convert it into gray\n",
    "    # (thresh, binary) = cv.threshold(grayframe, 127, 255, cv.THRESH_BINARY)  # takes grayframe as input and convert it into black and white\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    out.write(frame)  # takes frame as input and write it in output.avi\n",
    "    cv.imshow('frame', frame)  # takes grayframe/binary as input and display it grayframe/binary\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):  # press q to exit\n",
    "        break\n",
    "\n",
    "cap.release() # release the video capture object\n",
    "out.release() # release the video writer object\n",
    "cv.destroyAllWindows() # destroy all windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 17 = concatenate images\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "im1 = cv2.imread('resources/lena.png')\n",
    "im2 = cv2.imread('resources/Umair.jpg')\n",
    "\n",
    "im_v = cv2.vconcat([im1, im1])\n",
    "# cv2.imwrite('data/dst/opencv_vconcat.jpg', im_v)\n",
    "# True\n",
    "\n",
    "im_v_np = np.tile(im1, (2, 1, 1))\n",
    "# cv2.imwrite('data/dst/opencv_vconcat_np.jpg', im_v_np)\n",
    "# True\n",
    "\n",
    "def vconcat_resize_min(im_list, interpolation=cv2.INTER_CUBIC):\n",
    "    w_min = min(im.shape[1] for im in im_list)\n",
    "    im_list_resize = [cv2.resize(im, (w_min, int(im.shape[0] * w_min / im.shape[1])), interpolation=interpolation)\n",
    "                      for im in im_list]\n",
    "    return cv2.vconcat(im_list_resize)\n",
    "\n",
    "im_v_resize = vconcat_resize_min([im1, im2, im1])\n",
    "# cv2.imwrite('data/dst/opencv_vconcat_resize.jpg', im_v_resize)\n",
    "# True\n",
    "\n",
    "im_h = cv2.hconcat([im1, im1])\n",
    "# cv2.imwrite('data/dst/opencv_hconcat.jpg', im_h)\n",
    "# True\n",
    "\n",
    "im_h_np = np.tile(im1, (1, 2, 1))\n",
    "# cv2.imwrite('data/dst/opencv_hconcat_np.jpg', im_h_np)\n",
    "# True\n",
    "\n",
    "def hconcat_resize_min(im_list, interpolation=cv2.INTER_CUBIC):\n",
    "    h_min = min(im.shape[0] for im in im_list)\n",
    "    im_list_resize = [cv2.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation)\n",
    "                      for im in im_list]\n",
    "    return cv2.hconcat(im_list_resize)\n",
    "\n",
    "im_h_resize = hconcat_resize_min([im1, im2, im1])\n",
    "# cv2.imwrite('data/dst/opencv_hconcat_resize.jpg', im_h_resize)\n",
    "# True\n",
    "\n",
    "def concat_tile(im_list_2d):\n",
    "    return cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in im_list_2d])\n",
    "\n",
    "im1_s = cv2.resize(im1, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "im_tile = concat_tile([[im1_s, im1_s, im1_s, im1_s],\n",
    "                       [im1_s, im1_s, im1_s, im1_s],\n",
    "                       [im1_s, im1_s, im1_s, im1_s]])\n",
    "# cv2.imwrite('data/dst/opencv_concat_tile.jpg', im_tile)\n",
    "# True\n",
    "\n",
    "im_tile_np = np.tile(im1_s, (3, 4, 1))\n",
    "# cv2.imwrite('data/dst/opencv_concat_tile_np.jpg', im_tile_np)\n",
    "# True\n",
    "\n",
    "def concat_tile_resize(im_list_2d, interpolation=cv2.INTER_CUBIC):\n",
    "    im_list_v = [hconcat_resize_min(im_list_h, interpolation=cv2.INTER_CUBIC) for im_list_h in im_list_2d]\n",
    "    return vconcat_resize_min(im_list_v, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "im_tile_resize = concat_tile_resize([[im1],\n",
    "                                     [im1, im2, im1, im2, im1],\n",
    "                                     [im1, im2, im1]])\n",
    "# cv2.imwrite('data/dst/opencv_concat_tile_resize.jpg', im_tile_resize)\n",
    "# True\n",
    "\n",
    "\n",
    "# concatenate RGB and grayscale images\n",
    " \n",
    "# im1 = cv2.imread('resources/lena.png') # already defined above\n",
    "gray_im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "## won't work\n",
    "##horizontalAppendedIGrayImg = numpy.hstack((img,gray))\n",
    " \n",
    "grayImageBGRspace = cv2.cvtColor(gray_im1,cv2.COLOR_GRAY2BGR)\n",
    " \n",
    "horizontalAppendedIGrayImg = np.hstack((im1, grayImageBGRspace))\n",
    " \n",
    "\n",
    "\n",
    "# display images\n",
    "\n",
    "# cv2.imshow('im1', im1)\n",
    "# cv2.imshow('im2', im2)\n",
    "# cv2.imshow('im_v', im_v)\n",
    "# cv2.imshow('im_v_np', im_v_np)\n",
    "# cv2.imshow('im_v_resize', im_v_resize)\n",
    "# cv2.imshow('im_h', im_h)\n",
    "# cv2.imshow('im_h_np', im_h_np)\n",
    "# cv2.imshow('im_h_resize', im_h_resize)\n",
    "# cv2.imshow('im_tile', im_tile)\n",
    "# cv2.imshow('im_tile_np', im_tile_np)\n",
    "# cv2.imshow('im_tile_resize', im_tile_resize)\n",
    "\n",
    "cv2.imshow('Horizontal Appended Gray Img', horizontalAppendedIGrayImg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter 18 = image blending\n",
    "\n",
    "# Chapter 18 = Image blending\n",
    "\n",
    "# step 1: import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# step 2: function to read the images\n",
    "img1 = cv.imread('resources/lena.png')\n",
    "img2 = cv.imread('resources/image.jpg')\n",
    "\n",
    "# step 3: function to resize the images\n",
    "img1 = cv.resize(img1, (512, 512))\n",
    "img2 = cv.resize(img2, (512, 512))\n",
    "\n",
    "# step 4: function to blend the images\n",
    "dst = cv.addWeighted(img1, 0.7, img2, 0.3, 0) # (img1, weight1, img2, weight2, brightness) (weight1 + weight2 = 1)\n",
    "\n",
    "# step 5: function to display the images\n",
    "cv.imshow('image', dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 19 = Coordinates of an image on the screen and color of a pixel\n",
    "\n",
    "# step 1: import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# step 2: define a function to read coordinates of the mouse\n",
    "def click_event(event, x, y, flags, param): # x and y are the coordinates of the mouse\n",
    "    if event == cv.EVENT_LBUTTONDOWN: # if left button is pressed\n",
    "        print(x, ',', y) # print the coordinates of the mouse\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX # font of the text\n",
    "        strXY = str(x) + ', ' + str(y) # text to be displayed\n",
    "        cv.putText(img, strXY, (x, y), font, 0.5, (255, 255, 0), 2) # display the text on the image (img, text, coordinates, font, size, color, thickness)\n",
    "        cv.imshow('image', img) # display the image\n",
    "    if event == cv.EVENT_RBUTTONDOWN: # if right button is pressed\n",
    "        blue = img[y, x, 0] # blue color of the pixel (width, height, color channel)\n",
    "        green = img[y, x, 1] # green color of the pixel (width, height, color channel)\n",
    "        red = img[y, x, 2] # red color of the pixel (width, height, color channel)\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX # font of the text\n",
    "        strBGR = str(blue) + ', ' + str(green) + ', ' + str(red) # text to be displayed (BGR)\n",
    "        cv.putText(img, strBGR, (x, y), font, 0.5, (0, 255, 255), 2) # display the text on the image (img, text, coordinates, font, size, color, thickness)\n",
    "        cv.imshow('image', img) # display the image\n",
    "\n",
    "# step 3: function to read the image\n",
    "img = cv.imread('resources/lena.png')\n",
    "cv.imshow('image', img)\n",
    "\n",
    "# step 4: call the function\n",
    "cv.setMouseCallback('image', click_event)\n",
    "\n",
    "# step 5: wait for a key to be pressed\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 20 = split video into frames\n",
    "\n",
    "# step 1: import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# step 2: function to read the video\n",
    "cap = cv.VideoCapture('resources/web_output.avi') # read the video\n",
    "\n",
    "\n",
    "frame_count = 0 # frames counter\n",
    "\n",
    "# step 3: loop to read the video frame by frame\n",
    "while True:\n",
    "    success, frame = cap.read() # read the video frame by frame\n",
    "    if success == True: # if the video is read successfully\n",
    "        cv.imwrite(f'resources/frames/frame_' + str(frame_count) + '.jpg', frame) # save the image as a frame\n",
    "    else:\n",
    "        break\n",
    "    frame_count += 1 # increment the frame count by 1 or 2 and so on\n",
    "\n",
    "# step 4: release the video\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading streamlit-1.13.0-py2.py3-none-any.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 9.3 MB/s eta 0:00:00\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "     ------------------------------------- 812.8/812.8 kB 12.7 MB/s eta 0:00:00\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.9-py3-none-win_amd64.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=1.4\n",
      "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: protobuf!=3.20.2,<4,>=3.12 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (3.19.4)\n",
      "Collecting pyarrow>=4.0\n",
      "  Downloading pyarrow-9.0.0-cp310-cp310-win_amd64.whl (19.5 MB)\n",
      "     ---------------------------------------- 19.5/19.5 MB 8.7 MB/s eta 0:00:00\n",
      "Collecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "     ------------------------------------- 182.5/182.5 kB 10.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.2.0)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\muhammad umair\\appdata\\roaming\\python\\python310\\site-packages (from streamlit) (6.1)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0b4-py2.py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 9.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.27.1)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (1.4.1)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "     -------------------------------------- 237.5/237.5 kB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting blinker>=1.0.0\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting click>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.6/96.6 kB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (9.0.1)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (1.22.3)\n",
      "Collecting tzlocal>=1.1\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "     -------------------------------------- 164.8/164.8 kB 9.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.1.2)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.8/55.8 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: entrypoints in c:\\users\\muhammad umair\\appdata\\roaming\\python\\python310\\site-packages (from altair>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair>=3.2.0->streamlit) (4.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\muhammad umair\\appdata\\roaming\\python\\python310\\site-packages (from click>=7.0->streamlit) (0.4.4)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "     ---------------------------------------- 63.1/63.1 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.9.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=14.1->streamlit) (3.0.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (1.26.9)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "     ---------------------------------------- 51.1/51.1 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\muhammad umair\\appdata\\roaming\\python\\python310\\site-packages (from rich>=10.11.0->streamlit) (2.11.2)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.5-py2.py3-none-any.whl (336 kB)\n",
      "     ------------------------------------- 336.7/336.7 kB 10.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\muhammad umair\\appdata\\roaming\\python\\python310\\site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\muhammad umair\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (21.4.0)\n",
      "Building wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py): started\n",
      "  Building wheel for validators (setup.py): finished with status 'done'\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=20db08c3665615875e4435a6c2ad4433423442febd0d6bf5cc41f7b227dadfc6\n",
      "  Stored in directory: c:\\users\\muhammad umair\\appdata\\local\\pip\\cache\\wheels\\f2\\ed\\dd\\d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
      "Successfully built validators\n",
      "Installing collected packages: commonmark, zipp, watchdog, validators, tzdata, toolz, toml, smmap, semver, rich, pympler, pyarrow, click, blinker, pytz-deprecation-shim, pydeck, importlib-metadata, gitdb, tzlocal, gitpython, altair, streamlit\n",
      "Successfully installed altair-4.2.0 blinker-1.5 click-8.1.3 commonmark-0.9.1 gitdb-4.0.9 gitpython-3.1.29 importlib-metadata-5.0.0 pyarrow-9.0.0 pydeck-0.8.0b4 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-12.6.0 semver-2.13.0 smmap-5.0.0 streamlit-1.13.0 toml-0.10.2 toolz-0.12.0 tzdata-2022.5 tzlocal-4.2 validators-0.20.0 watchdog-2.1.9 zipp-3.9.0\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# building app using Streamlit\n",
    "######\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "st.write(\"\"\"\n",
    "# Simple Iris Flower Prediction App\n",
    "\n",
    "This app predicts the **Iris flower** type!\n",
    "\"\"\")\n",
    "\n",
    "st.sidebar.header('User Input Parameters')\n",
    "\n",
    "def user_input_features():\n",
    "    sepal_length = st.sidebar.slider('Sepal length', 4.3, 7.9, 5.4)\n",
    "    sepal_width = st.sidebar.slider('Sepal width', 2.0, 4.4, 3.4)\n",
    "    petal_length = st.sidebar.slider('Petal length', 1.0, 6.9, 1.3)\n",
    "    petal_width = st.sidebar.slider('Petal width', 0.1, 2.5, 0.2)\n",
    "    data = {'sepal_length': sepal_length,\n",
    "            'sepal_width': sepal_width,\n",
    "            'petal_length': petal_length,\n",
    "            'petal_width': petal_width}\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    return features\n",
    "\n",
    "df = user_input_features()\n",
    "\n",
    "st.subheader('User Input parameters')\n",
    "st.write(df)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "prediction = clf.predict(df)\n",
    "prediction_proba = clf.predict_proba(df)\n",
    "\n",
    "st.subheader('Class labels and their corresponding index number')\n",
    "st.write(iris.target_names)\n",
    "\n",
    "st.subheader('Prediction')\n",
    "st.write(iris.target_names[prediction])\n",
    "\n",
    "st.subheader('Prediction Probability')\n",
    "st.write(prediction_proba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 21 = how to detect specific color in an image\n",
    "\n",
    "# step 1: import libraries\n",
    "import cv2 as cv\n",
    "import cv2 as imshow\n",
    "import numpy as np\n",
    "\n",
    "# read image\n",
    "img = cv.imread('resources/lena.png')\n",
    "\n",
    "# convert to hsv (hue, saturation, value)\n",
    "hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV) # create hsv image\n",
    "\n",
    "# # slider for hsv\n",
    "# hue = 0-179\n",
    "# saturation = 0-255\n",
    "# value = 0-255\n",
    "# lower = np.array([h_min, s_min, v_min]) # lower bound\n",
    "# upper = np.array([h_max, s_max, v_max]) \n",
    "\n",
    "# # sliders\n",
    "# def slider(x): \n",
    "#     pass\n",
    "\n",
    "# cv.namedWindow('Tracking')\n",
    "# cv.createTrackbar('LH', 'Tracking', 0, 179, slider) # lower hue\n",
    "# cv.createTrackbar('LS', 'Tracking', 0, 255, slider) # lower saturation\n",
    "# cv.createTrackbar('LV', 'Tracking', 0, 255, slider) # lower value\n",
    "# cv.createTrackbar('UH', 'Tracking', 179, 179, slider) # upper hue\n",
    "# cv.createTrackbar('US', 'Tracking', 255, 255, slider) # upper saturation\n",
    "# cv.createTrackbar('UV', 'Tracking', 255, 255, slider) # upper value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # define range of blue color in hsv\n",
    "# lower_blue = np.array([110, 50, 50]) # lower bound of blue\n",
    "# upper_blue = np.array([130, 255, 255]) # upper bound of blue\n",
    "\n",
    "# # threshold the hsv image to get only blue colors\n",
    "# mask = cv.inRange(hsv_img, lower_blue, upper_blue) # mask = image with only blue\n",
    "\n",
    "# # bitwise and mask and original image\n",
    "# res = cv.bitwise_and(img, img, mask=mask) # res = image with only blue\n",
    "\n",
    "# show images\n",
    "cv.imshow('image', img)\n",
    "# cv.imshow('mask', mask)\n",
    "# cv.imshow('res', res)\n",
    "cv.imshow('hsv', hsv_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4e060e336c3e06b96e0eceb23c8fee58a924fcd5c0d73977daa382eea23651d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
